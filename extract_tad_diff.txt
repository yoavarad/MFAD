diff --git a/extract_tad_feature.py b/extract_tad_feature.py
index 0d32bd7..d5d12e2 100644
--- a/extract_tad_feature.py
+++ b/extract_tad_feature.py
@@ -12,6 +12,8 @@ from torchvision import transforms
 import models  # noqa: F401
 from dataset.loader import get_video_loader
 
+from tqdm import tqdm
+
 
 def to_normalized_float_tensor(vid):
     return vid.permute(3, 0, 1, 2).to(torch.float32) / 255
@@ -56,8 +58,8 @@ def get_args():
 
     parser.add_argument(
         '--data_set',
-        default='THUMOS14',
-        choices=['THUMOS14', 'FINEACTION'],
+        default='HMDB51_AD',
+        choices=['HMDB51_AD', 'HMDB-Violence', 'ped2', 'avenue', 'shanghaitech', 'UCF-Crime'],
         type=str,
         help='dataset')
 
@@ -87,25 +89,27 @@ def get_args():
 
 
 def get_start_idx_range(data_set):
-
     def thumos14_range(num_frames):
         return range(0, num_frames - 15, 4)
 
     def fineaction_range(num_frames):
         return range(0, num_frames - 15, 16)
 
+    def default_range(num_frames):
+        return range(0, num_frames - 15) #, 16)
+
     if data_set == 'THUMOS14':
         return thumos14_range
     elif data_set == 'FINEACTION':
         return fineaction_range
     else:
-        raise NotImplementedError()
+        return default_range
 
 
 def extract_feature(args):
     # preparation
     if not os.path.exists(args.save_path):
-        os.makedirs(args.save_path)
+        os.makedirs(args.save_path, exist_ok=True)
     video_loader = get_video_loader()
     start_idx_range = get_start_idx_range(args.data_set)
     transform = transforms.Compose(
@@ -114,14 +118,22 @@ def extract_feature(args):
 
     # get video path
     vid_list = os.listdir(args.data_path)
-    random.shuffle(vid_list)
+    vid_list.sort()
+    # random.shuffle(vid_list)
+
+    if 'ssv2' in args.ckpt_path:
+        num_classes = 174
+    elif 'k710' in args.ckpt_path:
+        num_classes = 710
+    else:
+        raise ValueError('Unknown model (check ckpt_path)')
 
     # get model & load ckpt
     model = create_model(
         args.model,
         img_size=224,
         pretrained=False,
-        num_classes=710,
+        num_classes=num_classes,
         all_frames=16,
         tubelet_size=2,
         drop_path_rate=0.3,
@@ -137,7 +149,7 @@ def extract_feature(args):
 
     # extract feature
     num_videos = len(vid_list)
-    for idx, vid_name in enumerate(vid_list):
+    for idx, vid_name in tqdm(enumerate(vid_list), desc='Extracting features', total=num_videos):
         url = os.path.join(args.save_path, vid_name.split('.')[0] + '.npy')
         if os.path.exists(url):
             continue
@@ -145,6 +157,8 @@ def extract_feature(args):
         video_path = os.path.join(args.data_path, vid_name)
         vr = video_loader(video_path)
 
+        print(vid_name, len(vr))
+
         feature_list = []
         for start_idx in start_idx_range(len(vr)):
             data = vr.get_batch(np.arange(start_idx, start_idx + 16)).asnumpy()
@@ -158,7 +172,7 @@ def extract_feature(args):
 
         # [N, C]
         np.save(url, np.vstack(feature_list))
-        print(f'[{idx} / {num_videos}]: save feature on {url}')
+        # print(f'[{idx} / {num_videos}]: save feature on {url}')
 
 
 if __name__ == '__main__':
